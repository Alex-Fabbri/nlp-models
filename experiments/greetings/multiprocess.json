{
  "dataset_reader": {
    "type" : "multiprocess",
    "num_workers" : 20,
  "base_reader": {
    "target_namespace": "joined_tokens",
    "type": "copynet",
    "truncate_source_len": 400,
    "truncate_target_len": 100,
    "source_tokenizer": 
    {
        "type" : "word",
        "word_splitter": 
        {
            "type": "simple"
        }

    },
    "source_token_indexers": {
      "tokens": {
        "type": "single_id",
        "namespace": "joined_tokens"
      },
      "token_characters": {
        "type": "characters"
      }
    },
    "target_token_indexers": {
      "tokens": {
        "namespace": "joined_tokens"
      }
    }

   }
  },
  "vocabulary": {
    "min_count": {
      "joined_tokens": 4
    },
    "tokens_to_add": {
        "joined_tokens": ["@COPY@"]
    }
  },
  "train_data_path": "data/greetings/multiple/train/train*",
  "validation_data_path": "data/greetings/multiple/valid/val*",
  "datasets_for_vocab_creation": ["train"],
  "model": {
    "type": "copynet",
    "source_namespace": "joined_tokens",
    "target_namespace": "joined_tokens",
    "source_embedder": {
      "tokens": {
        "type": "embedding",
        "vocab_namespace": "joined_tokens",
        "embedding_dim": 25,
        "trainable": true
      },
      "token_characters": {
        "type": "character_encoding",
        "embedding": {
          "embedding_dim": 10
        },
        "encoder": {
          "type": "lstm",
          "input_size": 10,
          "hidden_size": 10,
          "num_layers": 2,
          "dropout": 0,
          "bidirectional": true
        }
      }
    },
    "encoder": {
      "type": "lstm",
      "input_size": 45,
      "hidden_size": 100,
      "num_layers": 2,
      "dropout": 0,
      "bidirectional": true
    },
    "attention": {
      "type": "bilinear",
      "vector_dim": 200,
      "matrix_dim": 200
    },
    "target_embedding_dim": 10,
    "beam_size": 3,
    "max_decoding_steps": 20,
    "token_based_metric": {
      "type": "token_sequence_accuracy"
    }
  },
  "iterator": {
    "type": "multiprocess",
    "num_workers": 20,
    "base_iterator": 
    {
    "type": "bucket",
    "padding_noise": 0.0,
    "batch_size" : 32,
    "sorting_keys": [["source_tokens", "num_tokens"]]
    }
  },
  "trainer": {
    "optimizer": {
      "type": "sgd",
      "lr": 0.1
    },
    "learning_rate_scheduler": {
      "type": "cosine",
      "t_initial": 5,
      "t_mul": 1.5,
      "eta_mul": 0.9
    },
    "num_epochs": 2,
    "cuda_device": 0,
    "should_log_learning_rate": true,
    "should_log_parameter_statistics": false
  }
}
