{
  "dataset_reader": {
    "type": "language_modeling_fairseq",
    "lazy": true,
     "token_indexers":
      {
      "tokens":
        {
        "type": "single_id"
        }
     },
    "tokens_per_instance": 64
  },
  "train_data_path": "/home/fas/radev/af726/project/data/wikitext-2/wiki.train.tokens",
  "validation_data_path": "/home/fas/radev/af726/project/data/wikitext-2/wiki.valid.tokens",
  "test_data_path": "/home/fas/radev/af726/project/data/wikitext-2/wiki.test.tokens",
  "datasets_for_vocab_creation": "train",
  "vocabulary": {
     "min_count": {"tokens": 0},
     "max_vocab_size": {"tokens": 60000}
  },
  "model": {
    "type": "fairseq_transformer_lm",
    "eval_metric": "perplexity",
    "decoder_embed_dim": 512,
    "decoder_output_dim": 512,
    "decoder_input_dim": 512,
    "decoder_ffn_embed_dim": 2048,
    "decoder_layers": 6,
    "decoder_attention_heads": 8
  },
 "iterator": {
    "type": "basic",
    "batch_size" : 32
  },
"trainer": {
    "num_epochs": 20,
    "patience": 5,
    "cuda_device": 0,
    "grad_norm": 5.0,
    "optimizer": {
      "type": "sgd",
      "lr": 0.1
    },
    "learning_rate_scheduler": {
      "type": "exponential",
      "gamma": 0.99
    }
},
"evaluate_on_test": true

}
